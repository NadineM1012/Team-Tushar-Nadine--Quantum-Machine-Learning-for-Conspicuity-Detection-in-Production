{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAHUUZ9fw6rS",
        "outputId": "ac9198d4-fecf-40fe-afcd-698225b2e255"
      },
      "outputs": [],
      "source": [
        "# install libraries (quietly)\n",
        "!pip install pennylane -q\n",
        "!pip install kaggle -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXBKsfzex62m",
        "outputId": "b5df76a5-b92c-4a37-9964-41840ac3ec0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x274850451d0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importing libraries\n",
        "import json, os, time, copy, torch, pandas as pd, torchvision.transforms as transforms, pennylane as qml, torch.nn as nn, torch.optim as optim, torch.nn.functional as F\n",
        "from random import sample\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from pennylane import numpy as np\n",
        "from pennylane.templates import RandomLayers\n",
        "from torch.optim.lr_scheduler import StepLR,ReduceLROnPlateau, OneCycleLR, CosineAnnealingLR\n",
        "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Set the seed\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dDKsRtX8xIEr",
        "outputId": "b819afef-247b-49f3-8c3e-0dd1884f05ec"
      },
      "outputs": [],
      "source": [
        "# # Data donwload and unzip\n",
        "# !kaggle datasets download -d \"danielbacioiu/tig-aluminium-5083\"\n",
        "# !unzip tig-aluminium-5083.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YNs-SawRxNzd"
      },
      "outputs": [],
      "source": [
        "# Open the training file\n",
        "#f = open('/content/al5083/train/train.json') # Colab version\n",
        "f = open('al5083/train/train.json') # Local version\n",
        "data = json.load(f)\n",
        "\n",
        "# Create a dictionary to store the data\n",
        "data_dict = {0:[], 1:[], 2:[],\n",
        "             3:[], 4: [], 5:[]}\n",
        "for id, (key, value) in enumerate(data.items()):\n",
        "      data_dict[value].append(key)\n",
        "\n",
        "data_dict.pop(4)\n",
        "data_dict.pop(5)\n",
        "# Close the file\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jp3p1MH-yIFQ"
      },
      "outputs": [],
      "source": [
        "def sample_portion_each(data_dict, num_samples = 200):\n",
        "    # Sample a portion of each class\n",
        "    sampled_dict = {}\n",
        "    for key, value in data_dict.items():\n",
        "        if len(value) >= num_samples:\n",
        "            sampled_dict[key] = sample(value, num_samples)\n",
        "        else:\n",
        "            sampled_dict[key] = value\n",
        "    return sampled_dict\n",
        "\n",
        "# Sampled dictionary\n",
        "sampled_dict = sample_portion_each(data_dict, 200)\n",
        "\n",
        "# Create a dataframe for our dataset\n",
        "df = pd.DataFrame([(k, v) for k, values in sampled_dict.items() for v in values], columns=['label', 'img'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "294BCCBUzeS3"
      },
      "outputs": [],
      "source": [
        "# Dataset class\n",
        "class Aluminium5083Dataset(Dataset):\n",
        "    def __init__(self, df, transforms=None):\n",
        "        self.df = df\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the label corresponding to the Id\n",
        "        label = self.df.iloc[idx]['label']\n",
        "        # Get the image path\n",
        "        img_path = os.path.join('al5083/train/', self.df.iloc[idx]['img'])\n",
        "        # Open the image\n",
        "        img = Image.open(img_path)\n",
        "        # Binary labelling\n",
        "        #if label != 0:\n",
        "            #label = 1\n",
        "        # Convert the image to tensor\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "        # Return the image and label\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FuHSdbGX0qsV"
      },
      "outputs": [],
      "source": [
        "# Transform data to tensor, resize and renormalize it\n",
        "transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Resize((28, 28),antialias=False),\n",
        "                                transforms.Normalize([0.2428], [0.1344]),\n",
        "                                ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "85p-zYeX2L1g"
      },
      "outputs": [],
      "source": [
        "# Create the transformed dataset\n",
        "dataset = Aluminium5083Dataset(df=df, transforms=transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uZEZHq282Si-"
      },
      "outputs": [],
      "source": [
        "# Create a 70-20-10 split for train-validation-test\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.2 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "batch_size = 64\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size]) # Split the dataset\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  # Create a DataLoader for the train set\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  # Create a DataLoader for the validation set\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)  # Create a DataLoader for the test set\n",
        "\n",
        "dataloaders = {'train': train_loader, 'validation': val_loader, 'test':test_loader} # Create a dictionary for the dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Du6Sx_NU3EVR"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dev = qml.device(\"lightning.qubit\", wires=4)\n",
        "# Set the number of layers and the width of the circuit\n",
        "n_layers = 3\n",
        "n_wires = 4\n",
        "\n",
        "class Quanv(nn.Module):\n",
        "    def __init__(self,n_layers):\n",
        "        super(Quanv, self).__init__()\n",
        "        # Number of layers\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # Create a quantum circuit\n",
        "        @qml.qnode(dev,interface=\"torch\")\n",
        "        def circuit(inputs,weights):\n",
        "            # Angle Embedding and entanglement layers\n",
        "            qml.AngleEmbedding(inputs, wires=range(n_wires))\n",
        "            qml.BasicEntanglerLayers(weights, wires=range(n_wires))\n",
        "\n",
        "            # Measurement\n",
        "            return [qml.expval(qml.PauliZ(i)) for i in range(n_wires)]\n",
        "\n",
        "        # Add a torch layer using weight shapes\n",
        "        weight_shapes = {\"weights\": [self.n_layers, n_wires]}\n",
        "        self.circuit = qml.qnn.TorchLayer(circuit, weight_shapes=weight_shapes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the batch size, height, and width\n",
        "        bs, ch, h, w = x.size()\n",
        "        # Create a tensor to store the output\n",
        "        output = torch.zeros((bs, 4, 14, 14)).to(x.device)\n",
        "\n",
        "        # Loop over the coordinates of the top-left pixel of 2X2 squares\n",
        "        for b in range(bs):\n",
        "          for j in range(0, h, 2):\n",
        "              for k in range(0, w, 2):\n",
        "                  q_results = self.circuit(\n",
        "                      torch.tensor([\n",
        "                          x[b,0,j, k].item(),\n",
        "                          x[b,0,j, k + 1].item(),\n",
        "                          x[b,0,j + 1, k].item(),\n",
        "                          x[b,0,j + 1, k + 1].item()\n",
        "                      ]).to(x.device)\n",
        "                  )\n",
        "\n",
        "                  # Assign expectation values to different channels of the output pixel (j/2, k/2)\n",
        "                  for c in range(4):\n",
        "                     output[b,c,j // 2, k // 2] = q_results[c]\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_pGqdAy1nq86"
      },
      "outputs": [],
      "source": [
        "n_qubits = 4\n",
        "dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
        "@qml.qnode(dev)\n",
        "def qnode(inputs, weights):\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
        "\n",
        "n_layers = 4\n",
        "weight_shapes = {\"weights\": [n_layers, n_qubits]}\n",
        "qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DJSSYubk5vky"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs, batch_size):\n",
        "    since = time.time()\n",
        "    # Best model\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    best_loss = 10000.0\n",
        "    best_acc_train = 0.0\n",
        "    best_loss_train = 10000.0\n",
        "    print(\"Training started:\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Cross validation\n",
        "        for phase in [\"train\", \"validation\"]:\n",
        "            # Set model mode\n",
        "            if phase == \"train\":\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            n_batches = len(dataloaders[phase].dataset) // batch_size\n",
        "            # Batch iteration counter\n",
        "            it = 0\n",
        "            for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
        "                since_batch = time.time()\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == \"train\"):\n",
        "                    # Get outputs\n",
        "                    outputs = model(inputs)\n",
        "                    # Get predictions\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    # Compute loss using criterion\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    if phase == \"train\":\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                # Calculating the loss\n",
        "                running_loss += loss.item() * batch_size\n",
        "                # Calculating the accuracy\n",
        "                batch_corrects = torch.sum(preds == labels.data).item()\n",
        "                running_corrects += batch_corrects\n",
        "                # Print iteration counter\n",
        "                print(\"Phase: {} Epoch: {}/{} Iter: {}/{} Batch time: {:.4f}\".format(\n",
        "                        phase,\n",
        "                        epoch + 1,\n",
        "                        num_epochs,\n",
        "                        it + 1,\n",
        "                        n_batches + 1,\n",
        "                        time.time() - since_batch,\n",
        "                    ),\n",
        "                    end=\"\\r\",\n",
        "                    flush=True,\n",
        "                )\n",
        "                it += 1\n",
        "\n",
        "            # Print epoch results\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n",
        "            print(\n",
        "                \"Phase: {} Epoch: {}/{} Loss: {:.4f} Acc: {:.4f}        \".format(\n",
        "                    phase,\n",
        "                    epoch + 1,\n",
        "                    num_epochs,\n",
        "                    epoch_loss,\n",
        "                    epoch_acc,\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # Check if this is the best model wrt previous epochs\n",
        "            if phase == \"validation\" and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == \"validation\" and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "            if phase == \"train\" and epoch_acc > best_acc_train:\n",
        "                best_acc_train = epoch_acc\n",
        "            if phase == \"train\" and epoch_loss < best_loss_train:\n",
        "                best_loss_train = epoch_loss\n",
        "\n",
        "            # Update learning rate\n",
        "            if phase == \"validation\":\n",
        "                scheduler.step(epoch_loss)\n",
        "\n",
        "    # Print final results\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    time_elapsed = time.time() - since\n",
        "    print(\"Training completed in {:.0f}m {:.0f}s\".format(\n",
        "        time_elapsed // 60, time_elapsed % 60\n",
        "        ))\n",
        "    print(\"Best test loss: {:.4f} | Best test accuracy: {:.4f}\".format(best_loss, best_acc))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4VZg9Iy83bP",
        "outputId": "cd05179b-4f30-4a18-cde5-82f6d6902333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training started:\n",
            "Phase: train Epoch: 1/20 Loss: 1.1728 Acc: 0.5554        \n",
            "Phase: validation Epoch: 1/20 Loss: 1.1503 Acc: 0.6813        \n",
            "Phase: train Epoch: 2/20 Loss: 0.7603 Acc: 0.8054        \n",
            "Phase: validation Epoch: 2/20 Loss: 0.8316 Acc: 0.8313        \n",
            "Phase: train Epoch: 3/20 Loss: 0.4717 Acc: 0.8893        \n",
            "Phase: validation Epoch: 3/20 Loss: 0.6385 Acc: 0.8500        \n",
            "Phase: train Epoch: 4/20 Loss: 0.3141 Acc: 0.9089        \n",
            "Phase: validation Epoch: 4/20 Loss: 0.4670 Acc: 0.8750        \n",
            "Phase: train Epoch: 5/20 Loss: 0.2474 Acc: 0.9214        \n",
            "Phase: validation Epoch: 5/20 Loss: 0.3891 Acc: 0.8875        \n",
            "Phase: train Epoch: 6/20 Loss: 0.1959 Acc: 0.9321        \n",
            "Phase: validation Epoch: 6/20 Loss: 0.3172 Acc: 0.9062        \n",
            "Phase: train Epoch: 7/20 Loss: 0.1633 Acc: 0.9429        \n",
            "Phase: validation Epoch: 7/20 Loss: 0.2856 Acc: 0.9125        \n",
            "Phase: train Epoch: 8/20 Loss: 0.1496 Acc: 0.9518        \n",
            "Phase: validation Epoch: 8/20 Loss: 0.2317 Acc: 0.9437        \n",
            "Phase: train Epoch: 9/20 Loss: 0.1300 Acc: 0.9500        \n",
            "Phase: validation Epoch: 9/20 Loss: 0.2215 Acc: 0.9500        \n",
            "Phase: train Epoch: 10/20 Loss: 0.1156 Acc: 0.9589        \n",
            "Phase: validation Epoch: 10/20 Loss: 0.1902 Acc: 0.9500        \n",
            "Phase: train Epoch: 11/20 Loss: 0.1054 Acc: 0.9571        \n",
            "Phase: validation Epoch: 11/20 Loss: 0.1868 Acc: 0.9500        \n",
            "Phase: train Epoch: 12/20 Loss: 0.0961 Acc: 0.9625        \n",
            "Phase: validation Epoch: 12/20 Loss: 0.1621 Acc: 0.9625        \n",
            "Phase: train Epoch: 13/20 Loss: 0.0939 Acc: 0.9679        \n",
            "Phase: validation Epoch: 13/20 Loss: 0.1498 Acc: 0.9750        \n",
            "Phase: train Epoch: 14/20 Loss: 0.0800 Acc: 0.9714        \n",
            "Phase: validation Epoch: 14/20 Loss: 0.1435 Acc: 0.9625        \n",
            "Phase: train Epoch: 15/20 Loss: 0.0719 Acc: 0.9750        \n",
            "Phase: validation Epoch: 15/20 Loss: 0.1395 Acc: 0.9625        \n",
            "Phase: train Epoch: 16/20 Loss: 0.0633 Acc: 0.9839        \n",
            "Phase: validation Epoch: 16/20 Loss: 0.1273 Acc: 0.9812        \n",
            "Phase: train Epoch: 17/20 Loss: 0.0620 Acc: 0.9821        \n",
            "Phase: validation Epoch: 17/20 Loss: 0.1375 Acc: 0.9625        \n",
            "Phase: train Epoch: 18/20 Loss: 0.0562 Acc: 0.9857        \n",
            "Phase: validation Epoch: 18/20 Loss: 0.1163 Acc: 0.9812        \n",
            "Phase: train Epoch: 19/20 Loss: 0.0501 Acc: 0.9857        \n",
            "Phase: validation Epoch: 19/20 Loss: 0.1115 Acc: 0.9750        \n",
            "Phase: train Epoch: 20/20 Loss: 0.0457 Acc: 0.9893        \n",
            "Phase: validation Epoch: 20/20 Loss: 0.1197 Acc: 0.9688        \n",
            "Training completed in 892m 9s\n",
            "Best test loss: 0.1115 | Best test accuracy: 0.9812\n"
          ]
        }
      ],
      "source": [
        "# Sequential model\n",
        "model = torch.nn.Sequential(\n",
        "        Quanv(n_layers=3),\n",
        "        torch.nn.Flatten(),\n",
        "        torch.nn.Linear(in_features=14*14*4,out_features=4),\n",
        "        #qlayer,\n",
        "        torch.nn.Linear(in_features=4,out_features=4)\n",
        "    ).to(device)\n",
        "\n",
        "# Optimizer, Scheduler and loss criterion\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=5e-3, weight_decay=1e-5)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min',factor=0.1, patience=5,min_lr=0.00002)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "model= train_model(model, criterion, optimizer, scheduler, num_epochs=20, batch_size = batch_size)\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'model_multi_200_20.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWFKBC__9vzO",
        "outputId": "5a91d9ae-0ac0-4a8f-dc51-15035acadd10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the saved model\n",
        "model.load_state_dict(torch.load('model_multi_200_20.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4AXyHOho89cs"
      },
      "outputs": [],
      "source": [
        "def scores(y_true, y_pred, y_probs):\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    c_mat = confusion_matrix(y_true, y_pred)\n",
        "    roc = roc_auc_score(y_true, y_probs, multi_class='ovo', average='weighted')\n",
        "    print(\"f1 score:{:.2f}, roc:{:.2f}, precision:{:.2f}, recall:{:.2f}, confusion matrix:{}\".format(\n",
        "    f1, roc, precision, recall, c_mat))\n",
        "    return [f1,roc,precision, recall, c_mat]\n",
        "\n",
        "def predictions(loader):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    y_probs = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "            y_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    y_probs = np.array(y_probs)\n",
        "\n",
        "    model.train()\n",
        "    return y_true,y_pred, y_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZi4dpeL9p5x",
        "outputId": "e1f46ee0-e8fb-4c5c-cfb2-39b8941a706d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1 score:0.97, roc:1.00, precision:0.97, recall:0.97, confusion matrix:[[19  0  1  0]\n",
            " [ 0 18  0  0]\n",
            " [ 1  0 18  0]\n",
            " [ 0  0  0 23]]\n"
          ]
        }
      ],
      "source": [
        "y_true, y_pred, y_probs = predictions(test_loader)\n",
        "f1,roc,precision, recall, c_mat = scores(y_true, y_pred, y_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo0CnRz8-FpQ",
        "outputId": "535d218a-7c7d-461f-833e-5f129b24b187"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 97.5\n"
          ]
        }
      ],
      "source": [
        "accuracy = (np.array(y_pred) == np.array(y_true)).mean()\n",
        "print(\"Accuracy:\", 100*accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "0p4g73xfCnIH",
        "outputId": "1f8bca53-e17d-41f7-8ce2-bba6ced81128"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(c_mat, annot=True, fmt='d', cmap='Blues', xticklabels=range(4), yticklabels=range(4))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3qcWwywZyld"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
