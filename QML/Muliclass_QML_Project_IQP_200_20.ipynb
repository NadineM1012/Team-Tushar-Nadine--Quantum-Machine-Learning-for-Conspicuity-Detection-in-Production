{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAHUUZ9fw6rS",
        "outputId": "ac9198d4-fecf-40fe-afcd-698225b2e255"
      },
      "outputs": [],
      "source": [
        "# install libraries (quietly)\n",
        "!pip install pennylane -q\n",
        "!pip install kaggle -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXBKsfzex62m",
        "outputId": "b5df76a5-b92c-4a37-9964-41840ac3ec0f"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import json, os, time, copy, torch, pandas as pd, torchvision.transforms as transforms, pennylane as qml, torch.nn as nn, torch.optim as optim, torch.nn.functional as F\n",
        "from random import sample\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from pennylane import numpy as np\n",
        "from pennylane.templates import RandomLayers\n",
        "from torch.optim.lr_scheduler import StepLR,ReduceLROnPlateau, OneCycleLR, CosineAnnealingLR\n",
        "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Set the seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dDKsRtX8xIEr",
        "outputId": "b819afef-247b-49f3-8c3e-0dd1884f05ec"
      },
      "outputs": [],
      "source": [
        "# # Data donwload and unzip\n",
        "# !kaggle datasets download -d \"danielbacioiu/tig-aluminium-5083\"\n",
        "# !unzip tig-aluminium-5083.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YNs-SawRxNzd"
      },
      "outputs": [],
      "source": [
        "# Open the training file\n",
        "#f = open('/content/al5083/train/train.json') # Colab version\n",
        "f = open('al5083/train/train.json') # Local version\n",
        "data = json.load(f)\n",
        "\n",
        "# Create a dictionary to store the data\n",
        "data_dict = {0:[], 1:[], 2:[],\n",
        "             3:[], 4: [], 5:[]}\n",
        "for id, (key, value) in enumerate(data.items()):\n",
        "      data_dict[value].append(key)\n",
        "\n",
        "data_dict.pop(4)\n",
        "data_dict.pop(5)\n",
        "# Close the file\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jp3p1MH-yIFQ"
      },
      "outputs": [],
      "source": [
        "def sample_portion_each(data_dict, num_samples = 200):\n",
        "    # Sample a portion of each class\n",
        "    sampled_dict = {}\n",
        "    for key, value in data_dict.items():\n",
        "        if len(value) >= num_samples:\n",
        "            sampled_dict[key] = sample(value, num_samples)\n",
        "        else:\n",
        "            sampled_dict[key] = value\n",
        "    return sampled_dict\n",
        "\n",
        "# Sampled dictionary\n",
        "sampled_dict = sample_portion_each(data_dict, 200)\n",
        "\n",
        "# Create a dataframe for our dataset\n",
        "df = pd.DataFrame([(k, v) for k, values in sampled_dict.items() for v in values], columns=['label', 'img'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "294BCCBUzeS3"
      },
      "outputs": [],
      "source": [
        "# Dataset class\n",
        "class Aluminium5083Dataset(Dataset):\n",
        "    def __init__(self, df, transforms=None):\n",
        "        self.df = df\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the label corresponding to the Id\n",
        "        label = self.df.iloc[idx]['label']\n",
        "        # Get the image path\n",
        "        img_path = os.path.join('al5083/train/', self.df.iloc[idx]['img'])\n",
        "        # Open the image\n",
        "        img = Image.open(img_path)\n",
        "        # Binary labelling\n",
        "        #if label != 0:\n",
        "            #label = 1\n",
        "        # Convert the image to tensor\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "        # Return the image and label\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FuHSdbGX0qsV"
      },
      "outputs": [],
      "source": [
        "# Transform data to tensor, resize and renormalize it\n",
        "transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Resize((28, 28),antialias=False),\n",
        "                                transforms.Normalize([0.2428], [0.1344]),\n",
        "                                ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "85p-zYeX2L1g"
      },
      "outputs": [],
      "source": [
        "# Create the transformed dataset\n",
        "dataset = Aluminium5083Dataset(df=df, transforms=transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uZEZHq282Si-"
      },
      "outputs": [],
      "source": [
        "# Create a 70-20-10 split for train-validation-test\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.2 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "batch_size = 64\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size]) # Split the dataset\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  # Create a DataLoader for the train set\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  # Create a DataLoader for the validation set\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)  # Create a DataLoader for the test set\n",
        "\n",
        "dataloaders = {'train': train_loader, 'validation': val_loader, 'test':test_loader} # Create a dictionary for the dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Du6Sx_NU3EVR"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dev = qml.device(\"lightning.qubit\", wires=4)\n",
        "# Set the number of layers and the width of the circuit\n",
        "n_layers = 3\n",
        "n_wires = 4\n",
        "\n",
        "class Quanv(nn.Module):\n",
        "    def __init__(self,n_layers):\n",
        "        super(Quanv, self).__init__()\n",
        "        # Number of layers\n",
        "        self.n_layers = n_layers\n",
        "        # Create a quantum circuit\n",
        "        @qml.qnode(dev,interface=\"torch\")\n",
        "        def circuit(inputs,weights):\n",
        "            #qml.AngleEmbedding(inputs, wires=range(n_wires))\n",
        "            qml.IQPEmbedding(inputs.flatten(), wires = range(n_wires))\n",
        "            qml.BasicEntanglerLayers(weights, wires=range(n_wires))\n",
        "            # Measurement\n",
        "            return [qml.expval(qml.PauliZ(i)) for i in range(n_wires)]\n",
        "\n",
        "        # Add a torch layer using weight shapes\n",
        "        weight_shapes = {\"weights\": [self.n_layers,n_wires]}\n",
        "        #weight_shapes = {\"weights\": qml.StronglyEntanglingLayers.shape(n_layers=2, n_wires=n_wires)}\n",
        "        self.circuit = qml.qnn.TorchLayer(circuit, weight_shapes=weight_shapes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the batch size, height, and width\n",
        "        bs, ch, h, w = x.size()\n",
        "        # Create a tensor to store the output\n",
        "        output = torch.zeros((bs, 4, 14, 14)).to(x.device)\n",
        "\n",
        "        # Loop over the coordinates of the top-left pixel of 2X2 squares\n",
        "        for b in range(bs):\n",
        "          for j in range(0, h, 2):\n",
        "              for k in range(0, w, 2):\n",
        "                  q_results = self.circuit(\n",
        "                      torch.tensor([\n",
        "                          x[b,0,j, k].item(),\n",
        "                          x[b,0,j, k + 1].item(),\n",
        "                          x[b,0,j + 1, k].item(),\n",
        "                          x[b,0,j + 1, k + 1].item()\n",
        "                      ]).to(x.device)\n",
        "                  )\n",
        "\n",
        "                  # Assign expectation values to different channels of the output pixel (j/2, k/2)\n",
        "                  for c in range(4):\n",
        "                     output[b,c,j // 2, k // 2] = q_results[c]\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_pGqdAy1nq86"
      },
      "outputs": [],
      "source": [
        "n_qubits = 4\n",
        "dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
        "@qml.qnode(dev)\n",
        "def qnode(inputs, weights):\n",
        "    qml.IQPEmbedding(inputs, wires=range(n_qubits))\n",
        "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
        "\n",
        "n_layers = 4\n",
        "weight_shapes = {\"weights\": [n_layers, n_qubits]}\n",
        "#weight_shapes = {\"weights\":qml.StronglyEntanglingLayers.shape(n_layers=2, n_wires=n_qubits)}\n",
        "qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DJSSYubk5vky"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs, batch_size):\n",
        "    since = time.time()\n",
        "    # Best model\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    best_loss = 10000.0\n",
        "    best_acc_train = 0.0\n",
        "    best_loss_train = 10000.0\n",
        "    print(\"Training started:\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Cross validation\n",
        "        for phase in [\"train\", \"validation\"]:\n",
        "            # Set model mode\n",
        "            if phase == \"train\":\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            n_batches = len(dataloaders[phase].dataset) // batch_size\n",
        "            # Batch iteration counter\n",
        "            it = 0\n",
        "            for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
        "                since_batch = time.time()\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == \"train\"):\n",
        "                    # Get outputs\n",
        "                    outputs = model(inputs)\n",
        "                    # Get predictions\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    # Compute loss using criterion\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    if phase == \"train\":\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                # Calculating the loss\n",
        "                running_loss += loss.item() * batch_size\n",
        "                # Calculating the accuracy\n",
        "                batch_corrects = torch.sum(preds == labels.data).item()\n",
        "                running_corrects += batch_corrects\n",
        "                # Print iteration counter\n",
        "                print(\"Phase: {} Epoch: {}/{} Iter: {}/{} Batch time: {:.4f}\".format(\n",
        "                        phase,\n",
        "                        epoch + 1,\n",
        "                        num_epochs,\n",
        "                        it + 1,\n",
        "                        n_batches + 1,\n",
        "                        time.time() - since_batch,\n",
        "                    ),\n",
        "                    end=\"\\r\",\n",
        "                    flush=True,\n",
        "                )\n",
        "                it += 1\n",
        "\n",
        "            # Print epoch results\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n",
        "            print(\n",
        "                \"Phase: {} Epoch: {}/{} Loss: {:.4f} Acc: {:.4f}        \".format(\n",
        "                    phase,\n",
        "                    epoch + 1,\n",
        "                    num_epochs,\n",
        "                    epoch_loss,\n",
        "                    epoch_acc,\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # Check if this is the best model wrt previous epochs\n",
        "            if phase == \"validation\" and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == \"validation\" and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "            if phase == \"train\" and epoch_acc > best_acc_train:\n",
        "                best_acc_train = epoch_acc\n",
        "            if phase == \"train\" and epoch_loss < best_loss_train:\n",
        "                best_loss_train = epoch_loss\n",
        "\n",
        "            # Update learning rate\n",
        "            if phase == \"validation\":\n",
        "                scheduler.step(epoch_loss)\n",
        "\n",
        "    # Print final results\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    time_elapsed = time.time() - since\n",
        "    print(\"Training completed in {:.0f}m {:.0f}s\".format(\n",
        "        time_elapsed // 60, time_elapsed % 60\n",
        "        ))\n",
        "    print(\"Best test loss: {:.4f} | Best test accuracy: {:.4f}\".format(best_loss, best_acc))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4VZg9Iy83bP",
        "outputId": "cd05179b-4f30-4a18-cde5-82f6d6902333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training started:\n",
            "Phase: train Epoch: 1/20 Loss: 1.2098 Acc: 0.5893        \n",
            "Phase: validation Epoch: 1/20 Loss: 1.1213 Acc: 0.6875        \n",
            "Phase: train Epoch: 2/20 Loss: 0.8455 Acc: 0.7821        \n",
            "Phase: validation Epoch: 2/20 Loss: 0.8084 Acc: 0.8688        \n",
            "Phase: train Epoch: 3/20 Loss: 0.5790 Acc: 0.8768        \n",
            "Phase: validation Epoch: 3/20 Loss: 0.5734 Acc: 0.9062        \n",
            "Phase: train Epoch: 4/20 Loss: 0.3775 Acc: 0.9143        \n",
            "Phase: validation Epoch: 4/20 Loss: 0.4175 Acc: 0.9000        \n",
            "Phase: train Epoch: 5/20 Loss: 0.2568 Acc: 0.9357        \n",
            "Phase: validation Epoch: 5/20 Loss: 0.3033 Acc: 0.9125        \n",
            "Phase: train Epoch: 6/20 Loss: 0.1907 Acc: 0.9446        \n",
            "Phase: validation Epoch: 6/20 Loss: 0.2709 Acc: 0.9375        \n",
            "Phase: train Epoch: 7/20 Loss: 0.1569 Acc: 0.9554        \n",
            "Phase: validation Epoch: 7/20 Loss: 0.2244 Acc: 0.9375        \n",
            "Phase: train Epoch: 8/20 Loss: 0.1299 Acc: 0.9625        \n",
            "Phase: validation Epoch: 8/20 Loss: 0.2000 Acc: 0.9437        \n",
            "Phase: train Epoch: 9/20 Loss: 0.1153 Acc: 0.9643        \n",
            "Phase: validation Epoch: 9/20 Loss: 0.1776 Acc: 0.9437        \n",
            "Phase: train Epoch: 10/20 Loss: 0.0950 Acc: 0.9696        \n",
            "Phase: validation Epoch: 10/20 Loss: 0.1657 Acc: 0.9625        \n",
            "Phase: train Epoch: 11/20 Loss: 0.0825 Acc: 0.9786        \n",
            "Phase: validation Epoch: 11/20 Loss: 0.1539 Acc: 0.9500        \n",
            "Phase: train Epoch: 12/20 Loss: 0.0714 Acc: 0.9875        \n",
            "Phase: validation Epoch: 12/20 Loss: 0.1485 Acc: 0.9625        \n",
            "Phase: train Epoch: 13/20 Loss: 0.0624 Acc: 0.9893        \n",
            "Phase: validation Epoch: 13/20 Loss: 0.1315 Acc: 0.9625        \n",
            "Phase: train Epoch: 14/20 Loss: 0.0509 Acc: 0.9929        \n",
            "Phase: validation Epoch: 14/20 Loss: 0.1346 Acc: 0.9625        \n",
            "Phase: train Epoch: 15/20 Loss: 0.0454 Acc: 0.9929        \n",
            "Phase: validation Epoch: 15/20 Loss: 0.1243 Acc: 0.9563        \n",
            "Phase: train Epoch: 16/20 Loss: 0.0398 Acc: 0.9982        \n",
            "Phase: validation Epoch: 16/20 Loss: 0.1228 Acc: 0.9688        \n",
            "Phase: train Epoch: 17/20 Loss: 0.0365 Acc: 0.9946        \n",
            "Phase: validation Epoch: 17/20 Loss: 0.1171 Acc: 0.9500        \n",
            "Phase: train Epoch: 18/20 Loss: 0.0294 Acc: 1.0000        \n",
            "Phase: validation Epoch: 18/20 Loss: 0.1225 Acc: 0.9625        \n",
            "Phase: train Epoch: 19/20 Loss: 0.0259 Acc: 1.0000        \n",
            "Phase: validation Epoch: 19/20 Loss: 0.1153 Acc: 0.9437        \n",
            "Phase: train Epoch: 20/20 Loss: 0.0232 Acc: 1.0000        \n",
            "Phase: validation Epoch: 20/20 Loss: 0.1163 Acc: 0.9625        \n",
            "Training completed in 931m 27s\n",
            "Best test loss: 0.1153 | Best test accuracy: 0.9688\n"
          ]
        }
      ],
      "source": [
        "# Sequential model\n",
        "model = torch.nn.Sequential(\n",
        "        Quanv(n_layers=3),\n",
        "        torch.nn.Flatten(),\n",
        "        torch.nn.Linear(in_features=14*14*4,out_features=4),\n",
        "        torch.nn.Linear(in_features=4,out_features=4)\n",
        "    ).to(device)\n",
        "\n",
        "# Optimizer, Scheduler and loss criterion\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=5e-3, weight_decay=1e-5)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min',factor=0.1, patience=5,min_lr=0.00002)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "model= train_model(model, criterion, optimizer, scheduler, num_epochs=20, batch_size = batch_size)\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'model_multi_200_20_IQP.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWFKBC__9vzO",
        "outputId": "5a91d9ae-0ac0-4a8f-dc51-15035acadd10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the saved model\n",
        "model.load_state_dict(torch.load('model_multi_200_20_IQP.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4AXyHOho89cs"
      },
      "outputs": [],
      "source": [
        "def scores(y_true, y_pred, y_probs):\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    c_mat = confusion_matrix(y_true, y_pred)\n",
        "    roc = roc_auc_score(y_true, y_probs, multi_class='ovo', average='weighted')\n",
        "    print(\"f1 score:{:.2f}, roc:{:.2f}, precision:{:.2f}, recall:{:.2f}, confusion matrix:{}\".format(\n",
        "    f1, roc, precision, recall, c_mat))\n",
        "    return [f1,roc,precision, recall, c_mat]\n",
        "\n",
        "def predictions(loader):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    y_probs = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "            y_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    y_probs = np.array(y_probs)\n",
        "\n",
        "    model.train()\n",
        "    return y_true,y_pred, y_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZi4dpeL9p5x",
        "outputId": "e1f46ee0-e8fb-4c5c-cfb2-39b8941a706d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1 score:0.94, roc:0.99, precision:0.94, recall:0.94, confusion matrix:[[19  0  1  0]\n",
            " [ 0 18  0  0]\n",
            " [ 4  0 15  0]\n",
            " [ 0  0  0 23]]\n"
          ]
        }
      ],
      "source": [
        "y_true, y_pred, y_probs = predictions(test_loader)\n",
        "f1,roc,precision, recall, c_mat = scores(y_true, y_pred, y_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo0CnRz8-FpQ",
        "outputId": "535d218a-7c7d-461f-833e-5f129b24b187"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 93.75\n"
          ]
        }
      ],
      "source": [
        "accuracy = (np.array(y_pred) == np.array(y_true)).mean()\n",
        "print(\"Accuracy:\", 100*accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "0p4g73xfCnIH",
        "outputId": "1f8bca53-e17d-41f7-8ce2-bba6ced81128"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(c_mat, annot=True, fmt='d', cmap='Blues', xticklabels=range(4), yticklabels=range(4))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3qcWwywZyld"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
